# 0.25 dropout
# 49984/50000 [============================>.] - ETA: 0s - loss: 0.9163 - acc: 0.6773
# 50000/50000 [==============================] - 256s 5ms/step - loss: 0.9162 - acc: 0.6773 - val_loss: 0.8989 - val_acc: 0.6852

# 没有 dropout
# 49984/50000 [============================>.] - ETA: 0s - loss: 0.7824 - acc: 0.7249
# 50000/50000 [==============================] - 256s 5ms/step - loss: 0.7823 - acc: 0.7249 - val_loss: 0.8750 - val_acc: 0.6970

# 改成maxpool
# 49984/50000 [============================>.] - ETA: 0s - loss: 0.7500 - acc: 0.7376
# 50000/50000 [==============================] - 260s 5ms/step - loss: 0.7500 - acc: 0.7376 - val_loss: 0.8892 - val_acc: 0.6973

# a more deep model(epoch6)
# 49984/50000 [============================>.] - ETA: 0s - loss: 0.7744 - acc: 0.7281
# 50000/50000 [==============================] - 1738s 35ms/step - loss: 0.7744 - acc: 0.7281 - val_loss: 0.6897 - val_acc: 0.7623

# 78%准确率的结果
# 49984/50000 [============================>.] - ETA: 0s - loss: 0.6131 - acc: 0.7830
# 50000/50000 [==============================] - 568s 11ms/step - loss: 0.6131 - acc: 0.7830 - val_loss: 0.8148 - val_acc: 0.7245

# 正交 Seenta
# 1、 - 434s 9ms/step - loss: 1.6237 - acc: 0.3996 - val_loss: 1.3848 - val_acc: 0.4907
# 3、 - 451s 9ms/step - loss: 1.0741 - acc: 0.6211 - val_loss: 1.0344 - val_acc: 0.6420
# 6、 - 430s 9ms/step - loss: 0.8250 - acc: 0.7130 - val_loss: 0.8681 - val_acc: 0.6961
# 7、 - 435s 9ms/step - loss: 0.7715 - acc: 0.7344 - val_loss: 0.8525 - val_acc: 0.7061

# lecun uniform Seenta
# 1、 - 457s 9ms/step - loss: 1.6171 - acc: 0.4064 - val_loss: 1.4002 - val_acc: 0.4995
# 3、 - 607s 12ms/step - loss: 1.1071 - acc: 0.6080 - val_loss: 1.0384 - val_acc: 0.6295
# 6、 - 626s 13ms/step - loss: 0.8637 - acc: 0.6976 - val_loss: 0.8727 - val_acc: 0.6882
# 7、 - 466s 9ms/step - loss: 0.8206 - acc: 0.7132 - val_loss: 0.8928 - val_acc: 0.6829

# Xavier uniform Seenta
# 1、 - 426s 9ms/step - loss: 1.6283 - acc: 0.4009 - val_loss: 1.4117 - val_acc: 0.5019
# 3、 - 412s 8ms/step - loss: 1.1384 - acc: 0.5975 - val_loss: 1.0912 - val_acc: 0.6216
# 6、 - 613s 12ms/step - loss: 0.8512 - acc: 0.7010 - val_loss: 0.8615 - val_acc: 0.6981
# 7、 - 491s 10ms/step - loss: 0.8000 - acc: 0.7220 - val_loss: 0.8577 - val_acc: 0.7035

# default Seenta
# 1、 - 424s 8ms/step - loss: 1.6450 - acc: 0.3934 - val_loss: 1.4429 - val_acc: 0.4804
# 3、 - 425s 8ms/step - loss: 1.1388 - acc: 0.5956 - val_loss: 1.0901 - val_acc: 0.6136
# 6、 - 1073s 21ms/step - loss: 0.8778 - acc: 0.6933 - val_loss: 0.8974 - val_acc: 0.6830
# 7、 - 455s 9ms/step - loss: 0.8262 - acc: 0.7102 - val_loss: 0.9832 - val_acc: 0.6593

# Seenta 修改了layer bug 之后 （采用）
# 1、 - 416s 8ms/step - loss: 1.6152 - acc: 0.4034 - val_loss: 1.3813 - val_acc: 0.4994
# 3、 - 492s 10ms/step - loss: 1.0820 - acc: 0.6197 - val_loss: 1.0314 - val_acc: 0.6391
# 6、 - 420s 8ms/step - loss: 0.8348 - acc: 0.7080 - val_loss: 0.8916 - val_acc: 0.6917
# 7、 - 424s 8ms/step - loss: 0.7788 - acc: 0.7292 - val_loss: 0.8872 - val_acc: 0.6842
# 8、 - 425s 8ms/step - loss: 0.7353 - acc: 0.7440 - val_loss: 0.8316 - val_acc: 0.7070
# 10、 - 418s 8ms/step - loss: 0.6634 - acc: 0.7672 - val_loss: 0.8013 - val_acc: 0.7195

# Seenta的maxpooling层改为no padding（放弃）
# 1、 0.40
# 4、 0.58

# Seenta的maxpooling层改为2*2，no padding
# 3、 0.60

# 添加BatchNormalization（非常高）
# 1、 - 513s 10ms/step - loss: 1.5177 - acc: 0.4449 - val_loss: 1.1994 - val_acc: 0.5756
# 3、 - 610s 12ms/step - loss: 0.8727 - acc: 0.6917 - val_loss: 0.8825 - val_acc: 0.6904
（之前有严重的过拟合 val_acc降低到0.7以下）
# 6、 - 482s 10ms/step - loss: 0.6267 - acc: 0.7796 - val_loss: 0.7493 - val_acc: 0.7429
# 7、 - 480s 10ms/step - loss: 0.5721 - acc: 0.7998 - val_loss: 0.7832 - val_acc: 0.7372
# 8、 - 484s 10ms/step - loss: 0.5303 - acc: 0.8149 - val_loss: 0.7958 - val_acc: 0.7352
# 9、 - 494s 10ms/step - loss: 0.4906 - acc: 0.8299 - val_loss: 0.8430 - val_acc: 0.7270